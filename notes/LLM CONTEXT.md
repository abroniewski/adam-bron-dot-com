
**SYSTEM / ROLE**:  
You are a top-tier resume writer trained to parse multiple data sources (a JSON with career background and a job posting) and produce a **targeted Enhancv-style resume** that emphasizes the most relevant experiences, achievements, and skills for that specific job.

**USER**:  
I have two inputs:

1. A **JSON** document with my detailed career background.  
2. A **job posting** describing the target role.

Use them together to craft an **Enhancv-style resume** that highlights my qualifications in alignment with the job’s responsibilities and requirements. The sections and bullet points must adhere to the specified formatting guidelines and bullet lengths.

---

#### **JOB POSTING**  
About the job
Job Title

Microsoft Copilot Adoption Consultant

Job Description

Introduction

Are you passionate about artificial intelligence and its potential to transform business operations? Do you have experience in driving user adoption of Microsoft Co-pilot and other AI based new technologies. Do you have the mindset to drive optimization and utilization of existing applications? If so, you might be the adoption expert we are looking for!

What is the Digital Acceleration team?

The Digital Acceleration team is a brand new global team part of the ICT Support Organization. The goal of the team is to enhance business value for our ICT end users by driving user adoption of new technologies, such as artificial intelligence, and optimizing the utilization of existing applications, like the low-code platform and other tools. The team works closely with Business Stakeholders, ICT teams, and Software vendors to identify opportunities, develop use cases, and implement solutions that improve the efficiency, effectiveness, and satisfaction of our end users.

What will you be responsible for?

As the Microsoft CO-pilot adoption expert, you will be responsible for creating, maintaining and implementing the AI adoption strategy (using Co Pilot), across Vanderlande.
Work in partnership with the product team to identify potential areas for adoption, and transform technological advancements into actionable use cases.
Be an expert in AI technologies and continuously update knowledge on the latest trends.
Transforming technological advancements into actionable use cases.
Apply AI technologies to business operations in line with identified use cases.
Designing and conducting training sessions for end users.
Develop, train and nurture end users on using AI.
Organize and hosts events, like Hackathons, Workshops or Ideations sessions to increase adoption and the utilization of the AI in the organization. 

What do we need from you?

To be successful in this role, you should have

A bachelor's or master's degree in computer science, engineering, or a related field. Or work experience on similar level.
Experience in working with AI technologies, such as machine learning, natural language processing or computer vision etc.
Strong knowledge of the latest trends and developments in AI, and the ability to translate them into business value.
Excellent communication and presentation skills, and the ability to explain complex concepts in a simple and engaging way.
A passion for innovation and digital transformation
Has strong communication and presentation skills to engage and educate end users on the benefits and features of low code technologies
A customer-centric mindset and can understand the business needs and challenges of different stakeholders and able to convert this into practical solutions.
A collaborative and proactive attitude and can work well with cross-functional teams
Eagerness to learn new skills and technologies and share best practices with others.
A positive mindset, be proactive and open minded.

What We Offer

In this unique and challenging position, you will have the chance to make a significant contribution to industry-leading projects and be connected to our dedicated people and customers. We offer a position in an informal, international and professional working environment with a lot of scope for personal development. By joining our profitable and growing company you will be able to reach your goals and focus on your future.

This position offers a competitive salary range of € 4056,33 to € 5500 gross per month (excluding 8% holiday allowance). Through exceeding performance expectations, you even have the possibility to grow outside this scale.

On top of your fixed salary you’ll receive the following secondary benefits

40 vacation days (20 statutory days and a flexible budget worth 20 days). 
Flexible working hours. 
A hybrid workplace (40% working from home and 60% in the office). 
A Health & Wellbeing budget worth €300,- per calendar year.
Commuting allowance, including full reimbursement of travel by public transport. 
Working from home allowance. 
Collective pension scheme and discount on additional health insurance. 
On-site company health centres with a gym, physiotherapists and occupational therapists. 
Vanderlande Academy and training facilities to boost your skills. 
A variety in Vanderlande Network communities and initiatives. 
And a great company restaurant and coffee bar with barista.

Contact

Are you interested in this position? Then apply now directly on our workday vacancy link with your resume and motivation letter!

For more information about the position, please contact astha.singh@vanderlande.com.

PS Due to process compliance, we cannot process email applications. Kindly use the correct vacancy link to apply for this vacancy.

Diversity & Inclusion

Vanderlande is an equal opportunity/affirmative action employer. Qualified applicants will be considered without regards to race, religion, color, national origin, gender, sexual orientation, age, marital status, or disability status.

---


#### **JSON Data**  
{
  "personal_summary": {
    "headline": "Pipeline Integrity & Operations Specialist with a Passion for Culture and Continuous Improvement",
    "descriptions": [
      "Thrive in ambiguity, leading cross-functional teams to excel in both strategic planning and hands-on execution. Known for collaborative leadership, data-driven decision-making, and mentorship across diverse stakeholders."
    ]
  },
  "roles": [
{
  "title": "Founder",
  "company": "Moving Data Insights",
  "start_date": "2023-06",
  "end_date": "Present",
  "location": "Eindhoven, North Brabant, Netherlands (Hybrid)",
  "responsibilities": [
    "Set the company’s strategic direction and long-term growth trajectory, ensuring solutions remain innovative for clients in the mobility sector.",
    "Spearhead research collaborations with leading experts to develop cutting-edge AI/ML technologies, empowering clients to stay ahead of the curve.",
    "Engage with clients to understand unique challenges, translating domain knowledge into data-driven approaches and communicating results clearly.",
    "Manage business strategy and budget, balancing near-term consulting revenue with longer-term product/platform development.",
    "Implement Agile/Scrum practices internally and with clients, orchestrating sprint demos, retrospectives, and iterative project refinement.",
    "Mentor team members (co-founders, new hires) to enhance technical and client-facing skills, ensuring effective communication of project status and outcomes."
  ],
  "achievements": [
    {
      "achievement_point": "Empowered businesses to unlock new opportunities and significant bottom-line growth through strategic data insights and advanced analytics solutions.",
      "context": "Positioned MobilityDB (an open-source research project) as an industry leader, recognized for innovative data management and analytics."
    },
    {
      "achievement_point": "Committed to community engagement, mentoring future data-driven innovators, and contributing to industry thought leadership.",
      "context": "Hosted knowledge sessions, wrote newsletters, and engaged in open-source collaboration."
    },
    {
      "achievement_point": "Secured €20,000 in funding for customer validation; established 2 client projects valued at ~€10,000 each, fueling early traction.",
      "context": "Developed pitch decks, business proposals, and a viable sales funnel combining newsletter outreach and SME partnerships."
    },
    {
      "achievement_point": "Devised a 1-month PoC (Proof of Concept) product offering, allowing low-barrier data + AI trials for mid-sized clients.",
      "context": "Demonstrated agile approach and pre-scoped, lump-sum consulting engagements to reduce buyer hesitation."
    },
    {
      "achievement_point": "Built a data science pipeline to detect tax non-compliance, reducing audit time by 70% and achieving 93% accuracy in predicting unreported taxes.",
      "context": "Developed 9 engineered features, integrated 26 datasets, and used ML classification. Secured client’s government funding for MVP."
    },
    {
      "achievement_point": "Balanced short- vs. long-term goals, pivoting business strategy to maintain cash flow while focusing on strategic platform R&D.",
      "context": "Quantified opportunity costs and unknowns, refining risk management in project proposals and stakeholder communications."
    }
  ],
  "skills_utilized": [
    "Data Analytics & AI (ML, Process Mining)",
    "Business Strategy & Budget Management",
    "Client Relationship Management",
    "Agile Project Management (Scrum, Sprints, Retros)",
    "Technical Communication & Education",
    "Pitch Deck Creation & Investor Relations"
  ],
  "relevant_projects": [
    {
      "project_name": "Tax Non-Compliance Detection PoC",
      "description": "Developed a data-driven approach to flag high-risk accounts for auditing, reducing manual analysis time from 25 to 5 minutes.",
      "key_contribution": "Integrated 26 datasets, engineered 9 novel features, achieved 93% ML accuracy, and helped client secure government contract for MVP."
    },
    {
      "project_name": "1-Month PoC Product",
      "description": "Packaged consulting as a pre-scoped, low-barrier offering for mid-sized companies to experiment with AI solutions.",
      "key_contribution": "Created structured approach combining data pipelines, dashboards, and stakeholder education; attracted new clients."
    },
    {
      "project_name": "Big Data Management & Analysis Backbone",
      "description": "Proof of concept for IdleCompute (supercomputing startup) to demonstrate distributed data architecture with minimal overhead.",
      "key_contribution": "Applied DataOps best practices, built data collectors/storage (HDFS, Avro/Parquet/ORC), performed ML with Spark MLlib, and used an RDF knowledge graph for meta-data and analytics."
    }
  ],
  "interview_examples": {
    "situation": "Client wanted a PoC to detect tax fraud from historical filings. They had no ML background and required a demonstration for government funding.",
    "tasks": [
      "Acquired project via marketing/sales channels.",
      "Scoped PoC deliverables, set success metrics, and aligned on technical debt for MVP.",
      "Translated SME knowledge into data features, pivoted scope as new training data emerged.",
      "Communicated value at each stage, educating client on ML approach.",
      "Led dashboard design for story-telling from multiple angles (industry, location, etc.)."
    ],
    "actions": [
      "Combined daily SME calls with asynchronous Loom/Miro workflows to handle complex technical updates.",
      "Showed iterative results, including edge-case validations, via short screen recordings.",
      "Negotiated how to handle technical debt, turning debates into further expansions of project scope.",
      "Demonstrated ML trade-offs, including model pros/cons. Aligned features with client’s domain knowledge."
    ],
    "result": [
      "Reduced manual audit time by 70%. Achieved 93% accuracy predicting unreported taxes.",
      "Client extended contract and used pitch deck to secure government contract for MVP.",
      "Improved stakeholder trust and fostered a collaborative environment, leading co-founder to handle final project phases solo."
    ]
  }
}
    {
      "title": "Incident Response and Investigation Specialist",
      "company": "TC Energy",
      "start_date": "2016-04", 
      "end_date": "2021-07",
      "responsibilities": [
        "Oversee natural gas pipeline incident response, ensuring safe and compliant resolutions",
        "Facilitate cross-functional discussions with engineering, field technicians, and commercial teams for swift return-to-MOP strategies",
        "Build and maintain an 18-person on-call emergency preparedness team using tabletop exercises and curated playbooks",
        "Provide technical responses to regulatory bodies (e.g., NEB/CER), aligning with short- and long-term strategic goals"
      ],
      "achievements": [
        {
          "achievement_point": "Co-led a 6-person working group for a pipe integrity culture plan, onboarding 181 individuals with 96% survey completion",
          "context": "Presented plan to Pipe Integrity leadership; coached nine culture activity roadmaps"
        },
        {
          "achievement_point": "Developed an Ops Support Playbook in collaboration with Incident Response and Investigation teams",
          "context": "Standardized processes and improved quick execution/high-quality investigations, achieving cost and time savings"
        },
        {
          "achievement_point": "Drove an LDAR Facility Leak Response Escalation Process for clarity in RACI roles and reduced stakeholder overload",
          "context": "Feedback from regional leadership led to streamlining facility leaks response"
        },
        {
          "achievement_point": "Created a Third Party Gas Sampling Reference Document, preventing unnecessary outages and saving $300K–$500K per avoided excavation",
          "context": "Ensured clarity around planning, sampling, and lab analysis to confirm ethane levels"
        },
        {
          "achievement_point": "Implemented an Investigation & Verification of Natural Gas Leaks TOP update across CGO regions",
          "context": "Incorporated RACI roles and five years’ worth of lessons learned to simplify incident response"
        },
        {
          "achievement_point": "Organized formal kick-off for wildfire guidance, compiling decision-support info for operating or blowdown in wildfire scenarios",
          "context": "Worked with CGO Emergency Response Plan team to integrate guidance into controlled documents"
        },
        {
          "achievement_point": "Led and coached team members (e.g., Brian) through first investigations; submission had zero CER information requests",
          "context": "Demonstrates thoroughness and technical completeness"
        },
        {
          "achievement_point": "Authored multiple safety shares (YSYO program); helped 7 colleagues build personal safety plans and integrated %LEL awareness into incident protocols",
          "context": "Championed a safety-first culture, documented in Ops Support Playbook"
        },
        {
          "achievement_point": "Provided mentorship and coaching to interns (e.g., Sydney Liao) and colleagues, sharing a broader framework for intern development across Ops Support",
          "context": "Fostered a ‘3x multiplier effect’ in Incident Response and Investigation by enabling others"
        },
        {
          "achievement_point": "Participated in a 3-month digitization project (Avatar Program) with Suncor, Cenovus, Enbridge, NVA Energy",
          "context": "Contributed insights on indigenous relationships and innovative disruption"
        },
        {
          "achievement_point": "Served as Planning Section Chief for the 2017 Ludden +17 liquids leak in South Dakota",
          "context": "Prepared daily Incident Action Plans in a fast-paced environment; also served as Emergency Preparedness Coordinator for CGO Technical Services"
        },
        {
          "achievement_point": "Continuously refined mid-year and year-end goals, collaborating with CGO leadership to align culture efforts with strategic objectives",
          "context": "Enrolled in a 2-year master’s program complementing project/integrity management skills"
        }
      ],
      "skills_utilized": [
        "Incident Management",
        "Emergency Preparedness",
        "Root Cause Analysis",
        "Stakeholder Engagement",
        "Regulatory Compliance",
        "Mentorship/Coaching",
        "Ops Playbook Development"
      ],
      "relevant_projects": [
        {
          "project_name": "Ops Support Playbook",
          "description": "Detailed references for incident response, investigations, and return-to-MOP processes; formalizes lessons learned and fosters continuous improvement",
          "key_contribution": "Championed creation of standardized workflows and cross-team synergy"
        },
        {
          "project_name": "LDAR Facility Leak Response",
          "description": "Escalation process clarifying RACI roles and eliminating stakeholder overload",
          "key_contribution": "Drove initiative from feedback to streamlined solution"
        },
        {
          "project_name": "Third Party Gas Sampling Reference",
          "description": "Technical document to avoid outages and save $300K–$500K per excavation",
          "key_contribution": "Authored protocol ensuring clarity on sampling and lab analysis"
        },
        {
          "project_name": "Wildfire Guidance",
          "description": "Compiled operational decision-support for continuous pipeline operation vs. blowdown",
          "key_contribution": "Coordinated with CGO Emergency Response to integrate into controlled docs"
        }
      ]
    },
    {
      "title": "Project Manager – Pipe Integrity",
      "company": "TC Energy (Canada Gas Operations)",
      "start_date": "2013-12",
      "end_date": "2016-03",
      "responsibilities": [
        "Planned and executed 16 integrity projects (~$28M value), including emergency repairs and regulator-scrutinized endeavors",
        "Collaborated with contractors, environmental advisers, land divisions, and ops staff to define scope and meet schedules",
        "Supervised field execution, ensuring safe and cost-effective results"
      ],
      "achievements": [
        {
          "achievement_point": "Influenced cost estimation process by leveraging critical inquiry and strong relationships",
          "context": "Transitioned lessons learned into improved budgeting and scheduling frameworks"
        },
        {
          "achievement_point": "Developed standardized project closeout process with input from 16 stakeholder groups, closing out 121 projects successfully",
          "context": "Provided consistent turnover documentation and progress reporting for leadership"
        }
      ],
      "skills_utilized": [
        "Project Management",
        "Budget & Schedule Oversight",
        "Construction Supervision",
        "Conflict Resolution",
        "Cross-functional Negotiation"
      ]
    },
    {
      "title": "Engineering Intern – Major Projects (Alaska)",
      "company": "TC Energy",
      "start_date": "2011-09",
      "end_date": "2012-09",
      "responsibilities": [
        "Designed & implemented MS Access database to track regulatory info requests (~$40B project)",
        "Coordinated weekly updates with contractors and nine teams, balancing conflicting data needs",
        "Developed advanced communication skills via regular reporting to leadership"
      ],
      "achievements": [
        {
          "achievement_point": "Delivered a functional, inclusive database solution by empathizing with multiple teams’ requirements",
          "context": "Enhanced visibility for FERC requests, accelerating response times"
        }
      ],
      "skills_utilized": [
        "Database Design",
        "Regulatory Tracking",
        "Stakeholder Engagement",
        "Negotiation",
        "Technical Communication"
      ]
    }
  ],
  "education": [
    {
      "degree": "BSc Mechanical Engineering",
      "specialization": "Energy and Environment",
      "institution": "University of Calgary",
      "notes": "Focus on engineering principles applied to energy sector; completed 2013"
    },
    {
      "program": "Business Essentials",
      "institution": "University of Calgary",
      "topics_covered": [
        "Strategy formulation",
        "Financial decision making",
        "Negotiation",
        "Marketing",
        "Risk management",
        "Leadership training"
      ],
      "notes": "Enhances strategic planning for pipeline integrity and operational leadership"
    },
    {
  "degree": "MSc Big Data Management and Analytics",
  "institution": "Erasmus Mundus Program",
  "dates": "09/2021 – 09/2023",
  "locations": ["Brussels, BL", "Barcelona, ES", "Eindhoven, NL"],
  "summary_of_study": "Combined theory of data storage/processing with applied descriptive analytics, machine learning, and big data management. Emphasis on building scalable, flexible data architectures and knowledge graphs, evaluating technologies, and ethically deploying advanced analytics in real-world scenarios.",
  "key_points": [
    "Reduced PostgreSQL query time from 50+ minutes to 1.15s by implementing a new statistical method for query estimation.",
    "Built data pipeline architecture for a big data supercomputer startup using HDFS, Hadoop, and Apache PySpark.",
    "Developed semantic knowledge representation with RDFS/OWL; implemented a property graph ETL and knowledge graph ontology for distributed queries.",
    "Benchmarked relational vs. raster databases, assessing user-friendliness and data maintenance operations for business suitability.",
    "Analyzed medical data to predict heart disease via random forest, logistic regression, neural networks, and deep learning models."
  ],
  "technologies_and_libraries": [
    "Python", "R", "C++", "Java", "Bash",
    "SQL", "NoSQL (Cypher, SPARQL)",
    "PostgreSQL", "PostGIS", "MySQL",
    "Microsoft SQL", "Citus", "RasDaMan",
    "Neo4j", "GraphDB",
    "RDFS", "OWL",
    "HDFS", "Hadoop", "Spark ML", "GraphX", "PySpark",
    "Git", "Tableau", "PowerBI", "Kepler.gl",
    "BPMN", "TPC-DI", "TPC-DS"
  ],
  "courses": [
    "Advanced Databases & Database System Architecture",
    "OLAP/OLTP Data Warehouses",
    "Business Process Management (BPM)",
    "Data Mining & Machine Learning",
    "Distributed Systems for Big Data Management",
    "Ethics in Big Data",
    "Semantic Data Management (Ontologies, RDFS, OWL)",
    "Advanced Process Mining",
    "Empirical Methods in Software Engineering",
    "Longitudinal Data Analysis & Hypothesis Testing",
    "Event Knowledge Graphs for Process Mining"
  ],
  "major_projects": [
    {
      "project_name": "STIB Public Transport Data Analysis",
      "description": "Analyzed 12M+ real-time data points over 3 weeks for STIB network in Brussels. Managed missing unique IDs, performed on-time performance analysis, and built predictive passenger behavior models via time series methods (SARIMA, ACF/PACF) and ML. Visualized mobility data with Kepler.gl."
    },
    {
      "project_name": "Heart Disease Prediction",
      "description": "Cleaned and encoded medical data, selected features, and validated multiple ML algorithms (regressions, neural nets, random forest) for improved accuracy."
    },
    {
      "project_name": "Benchmarking RasDaMan vs. MS SQL",
      "description": "Evaluated raster database performance (RasDaMan) relative to MS SQL for business suitability, focusing on ETL, user-friendliness, and maintainability."
    },
    {
      "project_name": "TPC-DI and TPC-DS on MS SQL",
      "description": "Benchmarked database performance, running ETL and orchestration scripts, then analyzing results for optimization."
    },
    {
      "project_name": "Predicting Rejected Declarations in Travel Management System",
      "description": "Applied process mining to label data traces, balanced accuracy vs. earliness, and encoded process data for prediction models."
    },
    {
      "project_name": "Big Data Management & Analysis Backbone (IdleCompute Startup)",
      "description": "Developed a scalable data pipeline proof-of-concept leveraging DataOps. Designed and implemented data collectors, theoretical storage formats (ORC/Parquet/Avro), distributed temporal/persistent zones, and ML with Spark MLlib. Utilized RDF knowledge graph to manage metadata/graph analytics, culminating in a successful investor pitch for the startup."
    }
  ],
  "thesis": {
    "title": "Building a Digital Asset: An Event Knowledge Graph Approach for Integrating Data and Persisting Object-Centric Process Mining Analysis in Baggage Handling Systems",
    "abstract": "Examined how an Event Knowledge Graph can function as a flexible data model for Baggage Handling Systems (BHS). The approach streamlines data integration, feature generation, and persistent analysis across interconnected processes. Replicating past investigations with this novel approach reduced effort, improved understanding depth, and enabled perpetuation of analytical insights—transforming raw data into a sustainable digital asset."
  },
  "research_internship": {
    "topic": "MobilityDB / Grafana for Aviation Trajectory Analysis",
    "achievement_point": "Published paper, presented at symposium, showcasing how MobilityDB (PostgreSQL/PostGIS extension) can store and query large flight trajectory data. Combined with Grafana for advanced visualization. Demonstrated interactive queries for spatiotemporal data handling in open-source dashboards.",
    "paper_title": "Using MobilityDB and Grafana for Aviation Trajectory Analysis",
    "paper_keywords": [
      "moving objects",
      "MobilityDB",
      "Grafana",
      "open source",
      "dashboard"
    ],
    "context": "Applied advanced spatiotemporal queries to OpenSky Network flight data, enabling complex trajectory analysis beyond standard geospatial tools."
  },
  "state_of_the_art_paper": {
    "title": "State of the Art: A Review of Interoperability and Data Exchange in Healthcare",
    "abstract": "Reviewed interoperability standards, tools, and technologies in the healthcare industry. Focused on messaging/data-exchange protocols, semantics/ontologies, and big data analytics challenges. Explored middleware layers and how they facilitate data interchanges across clinical systems.",
    "keywords": [
      "interoperability",
      "data exchange",
      "healthcare",
      "semantics",
      "ontology",
      "standards",
      "big data"
    ]
  }
  ],
  "certifications": [
    // Potentially from other docs; not specifically extracted from the provided text
  ],
  "skills": [
    {
      "skill_name": "Pipeline Integrity",
      "sub_skills": [
        "Incident Response",
        "Inline Inspection (ILI)",
        "Direct Assessment",
        "LDAR Facility Leak Processes"
      ],
      "proficiency_level": "Expert",
      "tags": ["oil_and_gas", "compliance"]
    },
    {
      "skill_name": "Project Management",
      "sub_skills": [
        "Budgeting",
        "Scheduling",
        "Kanban",
        "Risk Mitigation"
      ],
      "proficiency_level": "Expert",
      "tags": ["agile_methods", "cross-functional"]
    },
    {
      "skill_name": "Emergency Preparedness",
      "sub_skills": [
        "EPC role",
        "On-call operations",
        "Playbook development"
      ],
      "tags": ["safety", "rapid_response"]
    },
    {
      "skill_name": "Mentorship & Coaching",
      "sub_skills": ["Intern development", "Reverse mentorship"],
      "tags": ["leadership", "culture"]
    }
  ],
  "languages": [
    {
      "language": "English",
      "proficiency": "Native"
    },
    {
      "language": "French",
      "proficiency": "Advanced"
    },
    {
      "language": "Polish",
      "proficiency": "Intermediate"
    }
  ],
  "volunteering": [
    {
      "role": "High School Alumni Committee Chair",
      "organization": "West Island College",
      "start_date": "2017-06",
      "end_date": "Present",
      "responsibilities": [
        "Developed tactics to execute the CEO’s vision and build an alumni mentorship community"
      ]
    },
    {
      "role": "Technical Writer",
      "organization": "NKA Wind Turbine Project",
      "start_date": "2016-06",
      "end_date": "2016-10",
      "responsibilities": [
        "Communicated complex engineering principles for Tanzanian workforce",
        "Established objectives and required tasks with project lead"
      ]
    }
  ],
  "projects_or_initiatives": [
    {
      "project_name": "3-month Digitization (Avatar Program)",
      "description": "Collaborated with Suncor, Cenovus, Enbridge, and NVA Energy on industrial digitization",
      "key_achievements": [
        "Provided insights on indigenous relationships, organizational disruption, and culture"
      ],
      "tags": ["digitization", "cross-industry", "culture"]
    },
    {
      "project_name": "Ops Support Culture Activities",
      "description": "Reinforced Ops Support team as leaders in clarifying decisions, role expectations, effective meeting discussions",
      "key_achievements": [
        "Led a 4-person Ops Support culture team for roadmap implementation"
      ],
      "tags": ["culture", "leadership", "conflict_resolution"]
    }
  ],
  "core_strengths": [
    {
      "strength_title": "Relationship Building",
      "description": "Bold vulnerability fosters open communication and cross-team trust"
    },
    {
      "strength_title": "Communication",
      "description": "Creates clear verbal and written plans; ensures alignment to minimize commercial impact"
    },
    {
      "strength_title": "Reflective",
      "description": "Uses empathetic questioning to understand experts’ perspectives and build attainable execution plans"
    },
    {
      "strength_title": "Energetic",
      "description": "Brings contagious enthusiasm and genuine interest to every project"
    }
  ],
  "additional_achievements": [
    {
      "achievement_description": "Developed an Ops Support Playbook that minimized downtime, enabling a consistent return-to-MOP strategy",
      "metric": "Reduced expenses & time for multiple pipeline incidents",
      "context": "Combined learnings from multiple regionally reported best practices"
    },
    {
      "achievement_description": "Flexsteel repair solution reduced pipeline outage by 29 days (~$2.4M cost avoidance)",
      "context": "Cross-collaboration between engineering, CRC, and field technicians"
    },
    {
      "achievement_description": "Participated in CEPA Emergency Working Group, planning cross-industry emergency response tabletop exercise",
      "context": "Highlighted Adam’s engagement with broader industry standards and best practices"
    }
  ]
}

---

#### **Required Resume Structure**  
**Header**  
1. **Name**  
2. **Professional Title(s)** (e.g., “Pipeline Integrity Engineer | Data Analytics Specialist | Story Teller”)  
3. **Email/Phone**  

**Summary**  
- 1–2 short paragraphs (2–4 lines).  
- Resourceful tone; no bullet points.  

**Achievement Highlights**  
- About **5 bullet points** total.  
- Each bullet: 1–2 lines, featuring a short “headline” (metric or result) + quick context.

**Experience** (reverse chronological)  
- **Role** – **Company**  
- **Dates**  
- **Location** (optional)  
- **2–4 bullet points** each, **1–2 lines** per bullet, focusing on results/scope relevant to the **job posting**.

**Certification & Training**  
- Short list format (1 line each if possible).

**Strengths**  
- 1–2 lines each.  
- e.g., **Strategic Planning**: “Short statement …”

**Languages**  
- List languages, optionally with proficiency.

**Education**  
- **Degree/Program**, **Institution**  
- **Graduation year**  
- 1–2 lines about specialization or results if relevant.

**Volunteering**  
- Role, organization, dates.  
- 1–2 lines about major duties or achievements.

**Skills**  
- Short bullet list or line items, e.g. “Root Cause Analysis,” “Python,” etc.

---

### **Stylistic Guidance**  
- All bullet points: **1–2 lines max**. Not too verbose.
- Use a ayout with each heading clearly labeled (for instance, “=====” or “======”).
- Write in a **professional, direct** style.  
- Focus on **achievements and outcomes** that align with the job posting.  
- The final answer: **plain text**.  
- The final resume should read well in 1–2 pages if exported.

### **TASK**  
1. Read my JSON background.  
2. Read the job posting.  
3. Select the experiences, achievements, and skills that best match the role.  
4. Generate an **Enhancv-style resume** with the headings: **Summary**, **Achievement Highlights**, **Experience**, **Certification & Training**, **Strengths**, **Languages**, **Education**, **Volunteering**, and **Skills** (in that order).  
5. Follow bullet length restrictions (1–2 lines).  
6. Maintain a top header with my name, desired professional titles, and contact info.

**END OF PROMPT**
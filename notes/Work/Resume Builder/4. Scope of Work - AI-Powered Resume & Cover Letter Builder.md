### 1. **Overview**

We are building a web-based AI-powered platform that allows users to generate tailored resumes and cover letters for specific job applications. The system is designed to:

* Extract and parse historical career data from uploaded files
* Analyze job postings and company information
* Generate personalized application documents using LLMs
* Guide users step-by-step via a chat interface
* Continuously refine and update a user-specific master context
* Export the final application as a downloadable PDF package

The system prioritizes ease of use, natural conversation, and minimal manual data entry. Users can complete the entire workflow through chat interaction, with the option to manually correct or edit content.

---

### 2. **System Architecture**

#### **Frontend**

* **Technology**: React (Vite or Next.js)
* **Hosting**: Railway or Vercel
* **Responsibilities**:

  * Provide a chat-based interface
  * Upload documents to Supabase Storage
  * Display generated content outlines and allow interaction
  * Authenticate users via Supabase Auth

#### **Backend**

* **Technology**: FastAPI (Python)
* **Hosting**: Railway
* **Responsibilities**:

  * Orchestrate the chat-driven workflow using a rules engine
  * Parse uploaded documents and extract relevant data
  * Evaluate user input, fetch prompts, and manage step progression
  * Communicate with OpenAI API for prompt generation and structured extraction

#### **Database**

* **Technology**: Supabase (PostgreSQL)
* **Responsibilities**:

  * Store user data, parsed elements, session states, step schemas
  * Manage authentication, session progress, and data enrichment

#### **LLM Integration**

* **API**: OpenAI GPT-4 or equivalent
* **Functions**:

  * Parse job descriptions and company info
  * Extract structured data from user-uploaded files
  * Generate chat responses, clarification prompts, and application drafts

---

### 3. **Business Logic Workflow**

#### Step 1: Build MASTER CONTEXT

* Users upload resumes, cover letters, performance reviews, or other artifacts
* Backend parses content and stores structured data as ELEMENTS in DB
* LLM may summarize and categorize content into experience, skills, achievements, etc.

#### Step 2: Parse JOB ROLE INFO

* User submits job description
* LLM extracts required skills, responsibilities, and keywords
* Output is stored as structured job requirement data

#### Step 3: Parse COMPANY INFO

* Optional user input: company name or website
* FastAPI scrapes website/news/blogs and summarizes values, culture, priorities

#### Step 4: Match MASTER CONTEXT to Role & Company

* Backend matches ELEMENTS from master context to the job description and company context
* Flags missing or weak areas, prepares outline mapping

#### Step 5: Fill Gaps & Enrich

* LLM prompts user with clarifying questions, suggestions, or quantification requests
* User responds in chat, and responses are parsed and stored as additional ELEMENTS

#### Step 6: Build RESUME & COVER LETTER OUTLINE

* Based on job + company + master context
* Assign which ELEMENTS go into resume vs. cover letter
* Store outline for review

#### Step 7: Outline Review with User

* User sees breakdown of what’s included where
* May accept, reject, or add manual items (via chat or manual input field)

#### Step 8: Values-Aligned Story Enrichment

* LLM prompts user to connect personal experiences to company values
* Adds to COVER LETTER ELEMENTS in master context

#### Step 9: Generate Documents

* Resume and cover letter are generated using predefined templates
* Output is stored and editable

#### Step 10: User Review & Edits

* User reviews draft via chat
* May request factual edits, tone changes, or style updates

#### Step 11: Export PDF Package

* Resume + cover letter exported as a bundled PDF for download

---

### 4. **Technical Components**

#### **Database Tables (Supabase)**

* `users`: auth & user info
* `sessions`: active user sessions and current step ID
* `conversation_steps`: step schema (id, key, prompt\_template, required\_fields, next\_step\_id)
* `resume_context`: structured field store (career\_summary, job\_1\_title, etc.)
* `parsed_elements`: extracted ELEMENTS from files (element\_type, content, source, confidence)
* `uploads`: file metadata and storage references

#### **Rules Engine (Python)**

* `is_step_complete(step, context)`: checks required fields
* `get_next_step(step_id, session_id)`: advances flow
* `build_prompt(step, context)`: generates LLM prompt with known values

#### **LLM Prompt Design**

* Prompt templates stored in DB per step
* Dynamic injection of known fields and OBJECTIVES
* Structured output parsing using OpenAI functions or JSON schema

#### **Upload Parsing Flow**

* User uploads file → stored in Supabase Storage
* File metadata saved in DB
* FastAPI fetches, parses file, uses LLM to extract structured elements
* Elements stored in `parsed_elements` and added to `resume_context`

---

### 5. **Key Features**

* Schema-driven step configuration (editable via Supabase GUI)
* LLM-powered natural conversation guidance
* Continuous enrichment of a unified master context
* Manual field updates via chat or typed correction
* Step-based progress tracking
* Support for multiple uploads, user corrections, and smart prompting
* Final export of personalized resume + cover letter as PDF

---

### 6. **Stretch Goals (Future)**

* Visual editing interface for resume section preview
* AI scoring / feedback on resume quality
* Job tracking and application follow-up assistant
* Multi-resume support for different industries or persona goals

---

### 7. **Next Steps**

* [ ] Set up Supabase project and define tables
* [ ] Scaffold FastAPI backend
* [ ] Define core `conversation_steps` and prompt templates
* [ ] Build basic React chat UI
* [ ] Connect React ↔ FastAPI ↔ Supabase roundtrip
* [ ] Begin testing resume-context gathering and prompting